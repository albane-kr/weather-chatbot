{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa55ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from CNN import SequenceCNN\n",
    "from torch.utils.data import DataLoader as TorchDataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04b1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from TemperatureDataset import TemperatureDataset\n",
    "from functools import partial\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab06300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:40<00:00, 13.77it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = TemperatureDataset('data_temp_max', 'data_temp_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c4aadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "batch_size = 32  # You can adjust this as needed\n",
    "\n",
    "train_loader = TorchDataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = TorchDataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = TorchDataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3a2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'hidden_dims': [32, 64],\n",
    "    'kernel_sizes': [5, 5],\n",
    "    'lr':  0.002507800985448251,\n",
    "    'batch_size': 32,\n",
    "    'activations': ['leaky_relu', 'relu'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eec8d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported activation: <class 'torch.nn.modules.activation.LeakyReLU'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m input_dim = sample_input.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m     17\u001b[39m output_dim = sample_target.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m best_model = \u001b[43mSequenceCNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhidden_dims\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkernel_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkernel_sizes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactivations\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m best_model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\henri\\Documents\\Uni.lu\\Semester 6\\BSP6\\weather-chatbot\\forecasting_service_training\\CNN.py:38\u001b[39m, in \u001b[36mSequenceCNN.__init__\u001b[39m\u001b[34m(self, input_dim, hidden_dims, kernel_sizes, output_dim, activations)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m act \u001b[38;5;129;01min\u001b[39;00m activations:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m act \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m activations_map:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported activation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mact\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mself\u001b[39m.activations.append(activations_map[act]())\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Build convolutional layers\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Unsupported activation: <class 'torch.nn.modules.activation.LeakyReLU'>"
     ]
    }
   ],
   "source": [
    "activations_map = {\n",
    "    'relu': torch.nn.ReLU,\n",
    "    'tanh': torch.nn.Tanh,\n",
    "    'sigmoid': torch.nn.Sigmoid,\n",
    "    'leaky_relu': torch.nn.LeakyReLU,\n",
    "    'elu': torch.nn.ELU,\n",
    "    'gelu': torch.nn.GELU,\n",
    "    'selu': torch.nn.SELU,\n",
    "    'none': nn.Identity\n",
    "}\n",
    "# Prepare activations\n",
    "\n",
    "# Build and train the best model on the full training set\n",
    "sample_input, sample_target = dataset[0]\n",
    "input_dim = sample_input.shape[-1]\n",
    "output_dim = sample_target.shape[-1]\n",
    "best_model = SequenceCNN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dims=list(best_params['hidden_dims']),\n",
    "    kernel_sizes=list(best_params['kernel_sizes']),\n",
    "    output_dim=output_dim,\n",
    "    activations=best_params['activations'],\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_params['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use the full train_loader for training\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    best_model.train()\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, targets = batch\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = best_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for inputs, targets in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = best_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # Save the best model\n",
    "            torch.save(best_model.state_dict(), 'best_model.pt')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = best_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
